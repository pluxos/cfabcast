akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logger-startup-timeout = 10s
  # To turn off logging
  #stdout-loglevel = "OFF"
  #loglevel = "OFF"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
#  loglevel = "INFO"
#  log-dead-letters = off
#  log-dead-letters-during-shutdown = off
#  log-config-on-start = on
 
  extensions = ["kamon.akka.Akka", "kamon.statsd.StatsD"]

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"

    serializers {
      # Define protobuf for akka
      proto = "akka.remote.serialization.ProtobufSerializer"
      # Define kryo serializer
      kryo = "com.romix.akka.serialization.kryo.KryoSerializer"
      cfabcaster = "cfabcast.serialization.CFABCastSerializer"
    }

    serialization-bindings {
      "cfabcast.messages.Message" = cfabcaster
      "cfabcast.messages.CFABCastMessage" = cfabcaster
    }

    kryo  {
      # Possibles values for type are: graph or nograph
      # graph supports serialization of object graphs with shared nodes
      # and cyclic references, but this comes at the expense of a small overhead
      # nograph does not support object grpahs with shared nodes, but is usually faster
      type = "graph"

      # Possible values for idstrategy are:
      # default, explicit, incremental
      # 
      # default - slowest and produces bigger serialized representation. Contains fully-
      # qualified class names (FQCNs) for each class. Note that selecting this strategy
      # does not work in version 0.3.2, but is available on master and from 0.3.3 onward.
      #  
      # explicit - fast and produces compact serialized representation. Requires that all
      # classes that will be serialized are pre-registered using the "mappings" and "classes"
      # sections. To guarantee that both sender and receiver use the same numeric ids for the same
      # classes it is advised to provide exactly the same entries in the "mappings" section
      # 
      # incremental - fast and produces compact serialized representation. Support optional
      # pre-registering of classes using the "mappings" and "classes" sections. If class is  
      # not pre-registered, it will be registered dynamically by picking a next available id
      # To guarantee that both sender and receiver use the same numeric ids for the same
      # classes it is advised to pre-register them using at least the "classes" section

      idstrategy = "incremental"  

      # Define a default size for serializer pool
      # Try to define the size to be at least as big as the max possible number
      # of threads that may be used for serialization, i.e. max number
      # of threads allowed for the scheduler
      serializer-pool-size = 16

      # Define a default size for byte buffers used during serialization   
      buffer-size = 4096  

      # The serialization byte buffers are doubled as needed until they exceed max-buffer-size and an exception is thrown. Can be -1 for no maximum.
      max-buffer-size = -1

      # If set, akka uses manifests to put a class name
      # of the top-level object into each message
      use-manifests = false

      # The transformations that have be done while serialization
      # Supported transformations: compression and encryption
      # accepted values(comma separated if multiple): off | lz4 | deflate | aes
      # Transformations occur in the order they are specified
      post-serialization-transformations = "lz4,aes"

      # Settings for aes encryption, if included in transformations
      # AES algo mode, key and custom key class can be specified
      # AES algo mode defaults to 'AES/CBC/PKCS5Padding' and key to 'ThisIsASecretKey'
      # If custom key class is provided, Kryo uses the class specified by a fully qualified class name
      # to get custom AES key. Such a class should define the method 'kryoAESKey'. 
      # This key overrides 'key'. If class doesn't contain 'kryoAESKey' method,
      # specified key is used. If this is not present, default key is used
      encryption {
        aes {
            mode = "AES/CBC/PKCS5Padding"
            key = j68KkRjq21ykRGAQ
      #      custom-key-class = "CustomAESKeyClass"
        }
      }

      # Log implicitly registered classes. Useful, if you want to know all classes
      # which are serialized. You can then use this information in the mappings and/or 
      # classes sections
      implicit-registration-logging = true 

      # If enabled, Kryo logs a lot of information about serialization process.
      # Useful for debugging and lowl-level tweaking
      kryo-trace = false 

      # If proviced, Kryo uses the class specified by a fully qualified class name
      # to perform a custom initialization of Kryo instances in addition to what
      # is done automatically based on the config file.
      kryo-custom-serializer-init = "cfabcast.serialization.CFABCastSerializer"

      # Define mappings from a fully qualified class name to a numeric id.  
      # Smaller ids lead to smaller sizes of serialized representations.  
      #  
      # This section is mandatory for idstartegy=explicit
      # This section is optional  for idstartegy=incremental  
      # This section is ignored   for idstartegy=default  
      #   
      # The smallest possible id should start at 20 (or even higher), because
      # ids below it are used by Kryo internally e.g. for built-in Java and 
      # Scala types   
      mappings {  
        "cfabcast.messages.Message" = 20,
        "cfabcast.messages.CFABCastMessage" = 21
      }  

      # Define a set of fully qualified class names for   
      # classes to be used for serialization.
      # The ids for those classes will be assigned automatically,
      # but respecting the order of declaration in this section  
      #  
      # This section is optional  for idstartegy=incremental  
      # This section is ignored   for idstartegy=default  
      # This section is optional  for idstartegy=explicit  
      classes = [
        "cfabcast.messages.Message",
        "cfabcast.messages.CFABCastMessage"
      ]  
    }
  }

  remote {
    transport = "akka.remote.netty.NettyRemoteTransport"
    netty.tcp {
      hostname = "127.0.0.1"
      port = 2551
    }

    log-remote-lifecycle-events = on
  }

  cluster {
    roles = [cfabcast]

    # Set seed node in a enviromment variable
    seed-nodes = [
      "akka.tcp://CFABCastSystem@127.0.0.1:2551"
    ]

    auto-down-unreachable-after = off
    metrics.enabled = off
    extensions = [
      "akka.contrib.pattern.ClusterReceptionistExtension",
      "com.romix.akka.serialization.kryo.KryoSerializationExtension$"
    ]
  }

#  persistence {
#     journal.plugin = "akka.persistence.journal.leveldb-shared"
#     journal.leveldb-shared.store {
        # FIXME: DO NOT USE 'native = off' IN PRODUCTION !
#        native = off
#        dir = "target/shared-journal"
#     }
#     snapshot-store.local.dir = "target/snapshots"
#  }
}

# Kamon Metrics

kamon {

  metric {

    # Time interval for collecting all metrics and send the snapshots to all subscribed actors.
    tick-interval = 1 seconds

    # Disables a big error message that will be typically logged if your application wasn't started
    # with the -javaagent:/path-to-aspectj-weaver.jar option. If you are only using KamonStandalone
    # it might be ok for you to turn this error off.
    disable-aspectj-weaver-missing-error = false

    # Specify if entities that do not match any include/exclude filter should be tracked.
    track-unmatched-entities = yes

    filters {
      akka-actor {
        includes = ["*/user/*", "*/user/node/*", "*/user/node/proposer*", "*/user/node/acceptor*", "*/user/node/learner*"]
        excludes = ["*/system/**", "*/user/IO-**", "*kamon*"]
      }

      akka-router {
        includes = ["*/user/*"]
        excludes = []
      }

      akka-dispatcher {
        includes = ["*/user/*"]
        excludes = []
      }

      trace {
        includes = [ "**" ]
        excludes = [ ]
      }
    }

  }

  # Controls whether the AspectJ Weaver missing warning should be displayed if any Kamon module requiring AspectJ is
  # found in the classpath but the application is started without the AspectJ Weaver.
  show-aspectj-missing-warning = yes

  statsd {

    # Hostname and port in which your StatsD is running. Remember that StatsD packets are sent using UDP and
    # setting unreachable hosts and/or not open ports wont be warned by the Kamon, your data wont go anywhere.
    hostname = "127.0.0.1"
    port = 8125

    # Interval between metrics data flushes to StatsD. It's value must be equal or greater than the
    # kamon.metric.tick-interval setting.
    flush-interval = 1 seconds

    # Max packet size for UDP metrics data sent to StatsD.
    max-packet-size = 1024 bytes

    # Subscription patterns used to select which metrics will be pushed to StatsD. Note that first, metrics
    # collection for your desired entities must be activated under the kamon.metrics.filters settings.
    subscriptions {
      histogram       = [ "**" ]
      min-max-counter = [ "**" ]
      gauge           = [ "**" ]
      counter         = [ "**" ]
      trace           = [ "**" ]
      trace-segment   = [ "**" ]
      akka-actor      = [ "**" ]
      akka-dispatcher = [ "**" ]
      akka-router     = [ "**" ]
      system-metric   = [ "**" ]
      http-server     = [ "**" ]
    }

    # FQCN of the implementation of `kamon.statsd.MetricKeyGenerator` to be instantiated and used for assigning
    # metric names. The implementation must have a single parameter constructor accepting a `com.typesafe.config.Config`.
    metric-key-generator = kamon.statsd.SimpleMetricKeyGenerator

    simple-metric-key-generator {

      # Application prefix for all metrics pushed to StatsD. The default namespacing scheme for metrics follows
      # this pattern:
      #    application.host.entity.entity-name.metric-name
      application = "cfabcast"

      # Includes the name of the hostname in the generated metric. When set to false, the scheme for the metrics
      # will look as follows:
      #    application.entity.entity-name.metric-name
      include-hostname = true

      # Allow users to override the name of the hostname reported by kamon. When changed, the scheme for the metrics
      # will have the following pattern:
      #   application.hostname-override-value.entity.entity-name.metric-name
      hostname-override = none

      # When the sections that make up the metric names have special characters like dots (very common in dispatcher
      # names) or forward slashes (all actor metrics) we need to sanitize those values before sending them to StatsD
      # with one of the following strategies:
      #   - normalize: changes ': ' to '-' and ' ', '/' and '.' to '_'.
      #   - percent-encode: percent encode the section on the metric name. Please note that StatsD doesn't support
      #     percent encoded metric names, this option is only useful if using our docker image which has a patched
      #     version of StatsD or if you are running your own, customized version of StatsD that supports this.
      metric-name-normalization-strategy = normalize
    }
  }
  
  modules {
    kamon-statsd.auto-start = true
    kamon-akka.auto-start = true
    kamon-akka-remote.auto-start = true
    kamon-system-metrics.auto-start = true
    kamon-log-reporter.auto-start = false
  }
}
